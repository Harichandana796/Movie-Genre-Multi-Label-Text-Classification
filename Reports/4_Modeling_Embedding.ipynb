{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#MODELING\" data-toc-modified-id=\"MODELING-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MODELING</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:59:09.873814Z",
     "start_time": "2019-03-13T21:58:39.074390Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0313 14:59:06.422702 24140 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smaiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\smaiya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "import functools \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import re\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "\n",
    "from helper_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:01:30.829828Z",
     "start_time": "2019-03-13T22:01:30.815792Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    unique_labels = functools.reduce(lambda l, x: l if x in l else l+[x], labels, [])\n",
    "    corr = np.inner(features, features)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "        corr,\n",
    "        xticklabels=unique_labels,\n",
    "        yticklabels=unique_labels,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(unique_labels, rotation=rotation)\n",
    "    ticks = np.linspace(len(features)/len(unique_labels)/2, len(features)-len(features)/len(unique_labels)/2, len(unique_labels), dtype=np.int)\n",
    "    g.set_xticks(ticks)\n",
    "    g.set_yticks(ticks)\n",
    "    g.set_title(\"Semantic Textual Similarity for: {}\".format(unique_labels))\n",
    "\n",
    "\n",
    "def run_and_plot(messages_, labels):\n",
    "    similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "    similarity_message_encodings = embed(similarity_input_placeholder)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())  \n",
    "        message_embeddings_ = session.run(similarity_message_encodings, feed_dict={similarity_input_placeholder: messages_})\n",
    "        plot_similarity(labels, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:01:32.634583Z",
     "start_time": "2019-03-13T22:01:32.624554Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_2d_representation(words_list, labels):\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        description_embeddings  =  session.run(embed(words_list)) #Generates the sentence embeddings\n",
    "        \n",
    "        model = PCA(n_components = 2) # Initializing the PCA object. We use n_components = 2 to help us plot our findings in the 2D space.\n",
    "        # Apply the fit_transform method of model to grains: pca_features\n",
    "        pca_features = model.fit_transform(description_embeddings) # Transforms embeddings to vectors of size 2\n",
    "        # Assign 0th column of pca_features: xs\n",
    "        xs = pca_features[:,0] #The first component of PCA\n",
    "        # Assign 1st column of pca_features: ys\n",
    "        ys = pca_features[:,1] #Second component of PCA\n",
    "        \n",
    "        #Next, we'll plot these results\n",
    "        #fig, ax = plt.subplots()\n",
    "        tmp = {}\n",
    "        label_idx = [tmp.setdefault(name, len(tmp)) for name in labels]\n",
    "        unique_labels = functools.reduce(lambda l, x: l if x in l else l+[x], labels, [])\n",
    "        df = pd.DataFrame({'x':xs, 'y': ys, 'label':label_idx})\n",
    "        colors = ['r', 'b', 'g', 'm', 'k']\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10,10)) \n",
    "        for idx in range(len(set(labels))):\n",
    "          ax.scatter(df[df['label']==idx].x, df[df['label']==idx].y, c=colors[idx], label=unique_labels[idx])\n",
    "        \n",
    "        ax.set(title='PCA Representation for Genres: {}'.format(unique_labels))\n",
    "        ax.legend()\n",
    "        #for i, txt in enumerate(words_list):\n",
    "        #    ax.annotate(txt, (xs[i], ys[i]), fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:01:45.786269Z",
     "start_time": "2019-03-13T22:01:40.028113Z"
    }
   },
   "outputs": [],
   "source": [
    "mydata_train = pd.read_csv('./../Data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "mydata_test = pd.read_csv('./../Data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "mydata = pd.read_csv('../Data/movies_genres.csv', delimiter='\\t')\n",
    "\n",
    "train_X, train_y = mydata_train['plot'], mydata_train.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "test_X, test_y = mydata_test['plot'], mydata_test.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "\n",
    "category_columns = train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:09:28.385563Z",
     "start_time": "2019-03-13T22:03:14.249284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 15:09:27.741820 24140 deprecation.py:323] From C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:15:32.162191Z",
     "start_time": "2019-03-13T22:09:52.067236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0313 15:10:35.485645 24140 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[310433,320] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5 (defined at C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py:517) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5', defined at:\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-25f71fab0278>\", line 3, in <module>\n    train_X_vector  =  session.run(embed(list(train_X))) #Generates the sentence embeddings\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 250, in __call__\n    name=name)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 517, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[310433,320] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5 (defined at C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py:517) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[310433,320] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-25f71fab0278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_X_vector\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Generates the sentence embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[310433,320] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5 (defined at C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py:517) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5', defined at:\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-25f71fab0278>\", line 3, in <module>\n    train_X_vector  =  session.run(embed(list(train_X))) #Generates the sentence embeddings\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 250, in __call__\n    name=name)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 517, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[310433,320] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node module_apply_default/Encoder_en/Transformer/PrepareForTransformer/embedding_lookup/GatherV2_5 (defined at C:\\Users\\smaiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py:517) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    train_X_vector  =  session.run(embed(list(train_X))) #Generates the sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
